---
- name: check | Initialize
  set_fact:
   scale_hdfs_nodes_list: []
   scale_hdfs_namenodes_list: []
   scale_hdfs_datanodes_list: []
   scale_hdfs_cluster: []

- debug:
    msg: "scale_hdfs_clusters: {{ scale_hdfs_clusters }}"
  run_once: true
  delegate_to: localhost

- name: check | Collect all hdfs list
  set_fact:
   scale_hdfs_cluster: "{{ item }}"
  when: scale_hdfs_cluster|length == 0
  with_items:
   - "{{ scale_hdfs_clusters }}"
  delegate_to: localhost
  run_once: true

- debug:
    msg: "scale_hdfs_cluster: {{ scale_hdfs_cluster }}"
  run_once: true
  delegate_to: localhost

- debug:
    msg: "scale_protocols: {{ scale_protocols }}"
  run_once: true
  delegate_to: localhost

- name: check | Check if hdfs is enabled
  assert:
   that:
   - scale_protocols.hdfs|bool
   fail_msg: "HDFS is not enabled"

- name: check |  Check if HDFS required information has been supplied.
  assert:
   that:
   - scale_hdfs_cluster is defined
   - scale_hdfs_cluster| length > 0
   - scale_hdfs_cluster.name is defined
   - scale_hdfs_cluster.name| length > 0
   - scale_hdfs_cluster.filesystem is defined
   - scale_hdfs_cluster.filesystem| length > 0
   - scale_hdfs_cluster.namenodes is defined
   - scale_hdfs_cluster.namenodes| length > 0
   - scale_hdfs_cluster.datanodes is defined
   - scale_hdfs_cluster.datanodes| length > 0
   - scale_hdfs_cluster.datadir is defined
   - scale_hdfs_cluster.datadir| length > 0
   fail_msg: "HDFS required parameter information is not defined."
   success_msg: "HDFS required information is defined."
  run_once: true
  delegate_to: localhost

- name: check | Collect all HDFS NameNodes
  set_fact:
   scale_hdfs_namenodes_list: "{{ scale_hdfs_cluster.namenodes | unique }}"
  delegate_to: localhost
  run_once: true

- debug:
    msg: "Collected all HDFS NameNodes: {{ scale_hdfs_namenodes_list }}"

- name: check | Collect all HDFS DataNodes
  set_fact:
   scale_hdfs_datanodes_list: "{{ scale_hdfs_cluster.datanodes | unique }}"
  delegate_to: localhost
  run_once: true

- debug:
        msg: "Collect all HDFS DataNodes: {{ scale_hdfs_datanodes_list }}"

- name: check | Get HDFS nodes
  set_fact:
    scale_hdfs_nodes_list: "{{ scale_hdfs_namenodes_list + scale_hdfs_datanodes_list }}"

- debug:
    msg: "Collect all HDFS nodes: {{ scale_hdfs_nodes_list }}"

- name: check | make unique HDFS nodes
  set_fact:
    scale_hdfs_nodes_list: "{{ scale_hdfs_nodes_list | unique }}"

- debug:
    msg: "Collect all HDFS nodes: {{ scale_hdfs_nodes_list }}"

- name: check | Check if atleast one hdfs node is configured
  assert:
   that:
   - scale_hdfs_nodes_list|length > 0
   fail_msg: "No hdfs nodes configured"

- name: "env_setup | Verify java"
  block:
    - name: "fetch JAVA_HOME path"
      shell: /usr/bin/echo $JAVA_HOME
      register: java_path

    - name: "fatch java path"
      find: 
        paths: /usr/lib,/usr/lib64
        file_type: file
        patterns: "javac"
        recurse: yes
      register: java_out
      when: java_path.stdout|length == 0

    - name: "set JAVA_HOME"
      set_fact:
        javahome_path: "{{ java_out.files[0].path | regex_replace('/bin/javac') }}"
      when: java_path.stdout|length == 0 and java_out.matched > 0

    - name: "set JAVA_HOME"
      set_fact:
         javahome_path: "{{ java_path.stdout }}"
      when: java_path.stdout|length > 0

    - debug: 
        var: javahome_path
        verbosity: 1

    - name: check | verify JAVA
      command: "/usr/bin/ls {{ javahome_path }}"
      register: jvm_list
      when: javahome_path|length > 0

    - fail:
        msg: "JAVA_HOME not set properlly"
      when: jvm_list.rc != 0

    - debug:
        msg: "HDFS Precheck ok"